import os
import cv2
import numpy as np
import random
import shutil
import json
from ultralytics import YOLO


def augment_data(dataset_path, augment_count=100):
    """æ•°æ®å¢å¼ºå¤„ç†ï¼ˆå¯¹åŸå§‹imageså’Œlabelsè¿›è¡Œå¢å¼ºï¼‰"""
    print(f"ğŸ”„ å¼€å§‹æ•°æ®å¢å¼º...ç›®æ ‡: {augment_count} å¼ ")

    images_dir = os.path.join(dataset_path, 'images')
    labels_dir = os.path.join(dataset_path, 'labels')

    if not os.path.exists(images_dir) or not os.path.exists(labels_dir):
        print("âš ï¸ å›¾åƒæˆ–æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®å¢å¼º")
        return

    image_files = [f for f in os.listdir(images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

    augmented_count = 0
    target_count = min(augment_count, len(image_files) * 2)  # æœ€å¤šå¢å¼ºåˆ°åŸå§‹æ•°æ®çš„2å€

    # æ‰“å°ç‰¹æ®Šå¤„ç†çš„æç¤º
    dehaze_printed = False
    gamma_printed = False

    while augmented_count < target_count and image_files:
        img_file = random.choice(image_files)
        img_path = os.path.join(images_dir, img_file)
        label_path = os.path.join(labels_dir,
                                  img_file.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt'))

        # æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(label_path):
            continue

        # è¯»å–åŸå§‹å›¾åƒ
        img = cv2.imread(img_path)
        if img is None:
            continue

        # éšæœºé€‰æ‹©å¢å¼ºæ–¹å¼
        choice = random.random()

        # 1. æ°´å¹³ç¿»è½¬
        if choice > 0.5:
            flipped_img = cv2.flip(img, 1)
            new_img_name = img_file.replace('.jpg', '_flip.jpg').replace('.png', '_flip.png').replace('.jpeg',
                                                                                                      '_flip.jpeg')
            new_img_path = os.path.join(images_dir, new_img_name)
            cv2.imwrite(new_img_path, flipped_img)
            copy_label_with_flip(label_path, new_img_name, img.shape[1]) if os.path.exists(label_path) else None

        # 2. äº®åº¦è°ƒæ•´
        elif choice > 0.4:
            brightness_factor = random.uniform(0.8, 1.2)
            bright_img = adjust_brightness(img, brightness_factor)
            new_img_name = img_file.replace('.jpg', '_bright.jpg').replace('.png', '_bright.png').replace('.jpeg',
                                                                                                          '_bright.jpeg')
            new_img_path = os.path.join(images_dir, new_img_name)
            cv2.imwrite(new_img_path, bright_img)
            copy_label(label_path, new_img_name) if os.path.exists(label_path) else None

        # 3. å¯¹æ¯”åº¦è°ƒæ•´
        elif choice > 0.3:
            contrast_factor = random.uniform(0.8, 1.2)
            contrast_img = adjust_contrast(img, contrast_factor)
            new_img_name = img_file.replace('.jpg', '_contrast.jpg').replace('.png', '_contrast.png').replace('.jpeg',
                                                                                                              '_contrast.jpeg')
            new_img_path = os.path.join(images_dir, new_img_name)
            cv2.imwrite(new_img_path, contrast_img)
            copy_label(label_path, new_img_name) if os.path.exists(label_path) else None

        # 4. é«˜æ–¯å™ªå£°
        elif choice > 0.2:
            noise_img = add_gaussian_noise(img)
            new_img_name = img_file.replace('.jpg', '_noise.jpg').replace('.png', '_noise.png').replace('.jpeg',
                                                                                                        '_noise.jpeg')
            new_img_path = os.path.join(images_dir, new_img_name)
            cv2.imwrite(new_img_path, noise_img)
            copy_label(label_path, new_img_name) if os.path.exists(label_path) else None

        # 5. æ—‹è½¬
        elif choice > 0.1:
            angle = random.uniform(-15, 15)
            rotated_img = rotate_image(img, angle)
            new_img_name = img_file.replace('.jpg', '_rot.jpg').replace('.png', '_rot.png').replace('.jpeg',
                                                                                                    '_rot.jpeg')
            new_img_path = os.path.join(images_dir, new_img_name)
            cv2.imwrite(new_img_path, rotated_img)
            copy_label(label_path, new_img_name) if os.path.exists(label_path) else None

        # 6. å¯¹é˜´é›¨å›¾åƒï¼šåŒç®—æ³•å®ç°å»é›¾+å¯¹æ¯”åº¦å¢å¼º
        else:
            dehazed_img = dehaze_image(img)
            enhanced_img = adjust_contrast(dehazed_img, random.uniform(1.1, 1.3))
            new_img_name = img_file.replace('.jpg', '_dehaze_contrast.jpg').replace('.png',
                                                                                    '_dehaze_contrast.png').replace(
                '.jpeg', '_dehaze_contrast.jpeg')
            new_img_path = os.path.join(images_dir, new_img_name)
            cv2.imwrite(new_img_path, enhanced_img)
            if not dehaze_printed:
                print(f"ğŸŒ§ï¸ å¯¹é˜´é›¨å›¾åƒï¼šä½¿ç”¨åŒç®—æ³•å®ç°å»é›¾+å¯¹æ¯”åº¦å¢å¼º")
                dehaze_printed = True
            copy_label(label_path, new_img_name) if os.path.exists(label_path) else None

        # 7. å¯¹é€†å…‰å›¾åƒï¼šè‡ªé€‚åº”gammaæ ¡æ­£
        if random.random() > 0.7:  # 30%æ¦‚ç‡åº”ç”¨gammaæ ¡æ­£
            gamma_corrected_img = adaptive_gamma_correction(img)
            new_img_name = img_file.replace('.jpg', '_gamma.jpg').replace('.png', '_gamma.png').replace('.jpeg',
                                                                                                        '_gamma.jpeg')
            new_img_path = os.path.join(images_dir, new_img_name)
            cv2.imwrite(new_img_path, gamma_corrected_img)
            if not gamma_printed:
                print(f"ğŸŒ… å¯¹é€†å…‰å›¾åƒï¼šä½¿ç”¨è‡ªé€‚åº”gammaæ ¡æ­£")
                gamma_printed = True
            copy_label(label_path, new_img_name) if os.path.exists(label_path) else None

        augmented_count += 1

    print(f"âœ… æ•°æ®å¢å¼ºå®Œæˆï¼Œæ–°å¢ {augmented_count} å¼ å¢å¼ºå›¾åƒ")


def dehaze_image(img):
    """ä½¿ç”¨æš—é€šé“å…ˆéªŒç®—æ³•è¿›è¡Œå»é›¾"""
    img_float = img.astype(np.float64) / 255.0
    dark_channel = np.min(img_float, axis=2)
    img_size = img_float.shape[:2]
    num_brightest = int(0.001 * img_size[0] * img_size[1])
    dark_vec = dark_channel.reshape(-1)
    indices = np.argsort(dark_vec)[::-1][:num_brightest]
    brightest_pixels = img_float.reshape(-1, 3)[indices]
    A = np.max(brightest_pixels, axis=0)
    omega = 0.95
    t = 1 - omega * dark_channel
    t = np.maximum(t, 0.1)
    img_dehazed = np.zeros_like(img_float)
    for i in range(3):
        img_dehazed[:, :, i] = (img_float[:, :, i] - A[i]) / t + A[i]
    img_dehazed = np.clip(img_dehazed, 0, 1)
    return (img_dehazed * 255).astype(np.uint8)


def adaptive_gamma_correction(img):
    """è‡ªé€‚åº”gammaæ ¡æ­£"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    mean_brightness = np.mean(gray)
    if mean_brightness < 100:
        gamma = 0.6 + random.uniform(0, 0.2)
    elif mean_brightness > 155:
        gamma = 1.2 + random.uniform(0, 0.2)
    else:
        gamma = 0.9 + random.uniform(0, 0.2)
    inv_gamma = 1.0 / gamma
    table = np.array([((i / 255.0) ** inv_gamma) * 255 for i in np.arange(0, 256)]).astype("uint8")
    return cv2.LUT(img, table)


def copy_label(original_label_path, new_img_name):
    """å¤åˆ¶æ ‡ç­¾æ–‡ä»¶"""
    new_label_name = new_img_name.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')
    new_label_path = original_label_path.replace(os.path.basename(original_label_path), new_label_name)
    with open(original_label_path, 'r') as src:
        content = src.read()
    with open(new_label_path, 'w') as dst:
        dst.write(content)


def copy_label_with_flip(original_label_path, new_img_name, img_width):
    """å¤åˆ¶æ ‡ç­¾æ–‡ä»¶å¹¶ä¿®æ”¹æ°´å¹³ç¿»è½¬åçš„åæ ‡"""
    new_label_name = new_img_name.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')
    new_label_path = original_label_path.replace(os.path.basename(original_label_path), new_label_name)
    with open(original_label_path, 'r') as src:
        lines = src.readlines()
    with open(new_label_path, 'w') as dst:
        for line in lines:
            parts = line.strip().split()
            if len(parts) >= 5:
                class_id = parts[0]
                x_center = 1.0 - float(parts[1])  # æ°´å¹³ç¿»è½¬ï¼š1 - x_center
                y_center = float(parts[2])
                width = float(parts[3])
                height = float(parts[4])
                x_center = max(0.0, min(1.0, x_center))
                y_center = max(0.0, min(1.0, y_center))
                width = max(0.0, min(1.0, width))
                height = max(0.0, min(1.0, height))
                dst.write(f"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\n")
            else:
                dst.write(line)


def adjust_brightness(img, factor):
    """è°ƒæ•´å›¾åƒäº®åº¦"""
    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)
    hsv = hsv.astype(np.float64)
    hsv[:, :, 1] = hsv[:, :, 1] * factor
    hsv[:, :, 1] = np.clip(hsv[:, :, 1], 0, 255)
    hsv = hsv.astype(np.uint8)
    return cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)


def adjust_contrast(img, factor):
    """è°ƒæ•´å›¾åƒå¯¹æ¯”åº¦"""
    img_contrast = img.astype(np.float64)
    img_contrast = (img_contrast - 127.5) * factor + 127.5
    img_contrast = np.clip(img_contrast, 0, 255)
    img_contrast = img_contrast.astype(np.uint8)
    return img_contrast


def add_gaussian_noise(img, mean=0, std=25):
    """æ·»åŠ é«˜æ–¯å™ªå£°"""
    noise = np.random.normal(mean, std, img.shape).astype(np.float32)
    noisy_img = img.astype(np.float32) + noise
    noisy_img = np.clip(noisy_img, 0, 255)
    return noisy_img.astype(np.uint8)


def rotate_image(img, angle):
    """æ—‹è½¬å›¾åƒ"""
    h, w = img.shape[:2]
    center = (w // 2, h // 2)
    rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
    return cv2.warpAffine(img, rotation_matrix, (w, h))


def split_dataset(dataset_path):
    """æ•°æ®é›†åˆ’åˆ†ï¼šè®­ç»ƒé›†70%ï¼ŒéªŒè¯é›†20%ï¼Œæµ‹è¯•é›†10%"""
    print("ğŸ”„ å¼€å§‹æ•°æ®é›†åˆ’åˆ†...")

    images_dir = os.path.join(dataset_path, 'images')
    labels_dir = os.path.join(dataset_path, 'labels')

    # è·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    all_image_files = []
    for root, dirs, files in os.walk(images_dir):
        for file in files:
            if file.lower().endswith(('.jpg', '.jpeg', '.png')):
                if not any(subdir in root for subdir in ['train', 'val', 'test']):
                    all_image_files.append(os.path.relpath(os.path.join(root, file), images_dir))

    # è¿‡æ»¤æ‰æ²¡æœ‰å¯¹åº”æ ‡ç­¾çš„å›¾åƒ
    valid_files = []
    for img_file in all_image_files:
        label_name = img_file.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')
        label_path = os.path.join(labels_dir, label_name)
        if os.path.exists(label_path):
            with open(label_path, 'r') as f:
                content = f.read().strip()
                if content:
                    valid_files.append(img_file)

    print(f"âœ… æ‰¾åˆ° {len(valid_files)} ä¸ªæœ‰æ ‡ç­¾çš„å›¾åƒ")

    if len(valid_files) == 0:
        raise ValueError("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å¸¦æ ‡ç­¾çš„å›¾åƒï¼è¯·æ£€æŸ¥æ ‡ç­¾æ–‡ä»¶æ˜¯å¦æ­£ç¡®ã€‚")

    # éšæœºæ‰“ä¹±
    random.shuffle(valid_files)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    for dir_path in ['images/train', 'images/val', 'images/test', 'labels/train', 'labels/val', 'labels/test']:
        os.makedirs(os.path.join(dataset_path, dir_path), exist_ok=True)

    # è®¡ç®—åˆ’åˆ†æ¯”ä¾‹
    total = len(valid_files)
    train_size = int(0.7 * total)
    val_size = int(0.2 * total)

    # åˆ†å‰²æ•°æ®
    train_files = valid_files[:train_size]
    val_files = valid_files[train_size:train_size + val_size]
    test_files = valid_files[train_size + val_size:]

    # ç§»åŠ¨æ–‡ä»¶
    move_files(train_files, images_dir, labels_dir, f'{dataset_path}/images/train', f'{dataset_path}/labels/train')
    move_files(val_files, images_dir, labels_dir, f'{dataset_path}/images/val', f'{dataset_path}/labels/val')
    move_files(test_files, images_dir, labels_dir, f'{dataset_path}/images/test', f'{dataset_path}/labels/test')

    print(f"âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆ: è®­ç»ƒé›†{len(train_files)}å¼ ï¼ŒéªŒè¯é›†{len(val_files)}å¼ ï¼Œæµ‹è¯•é›†{len(test_files)}å¼ ")


def move_files(file_list, src_img_dir, src_lbl_dir, dst_img_dir, dst_lbl_dir):
    """ç§»åŠ¨æ–‡ä»¶åˆ°ç›®æ ‡ç›®å½•"""
    for file_name in file_list:
        src_img_path = os.path.join(src_img_dir, file_name)
        dst_img_path = os.path.join(dst_img_dir, file_name)
        if os.path.exists(src_img_path):
            shutil.copy2(src_img_path, dst_img_path)
        label_name = file_name.replace('.jpg', '.txt').replace('.png', '.txt').replace('.jpeg', '.txt')
        src_lbl_path = os.path.join(src_lbl_dir, label_name)
        dst_lbl_path = os.path.join(dst_lbl_dir, label_name)
        if os.path.exists(src_lbl_path):
            shutil.copy2(src_lbl_path, dst_lbl_path)


def test_model_on_test_set():
    """ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šè¿›è¡Œè¯„ä¼°"""
    print("ğŸ§ª å¼€å§‹åœ¨æµ‹è¯•é›†ä¸Šæµ‹è¯•æ¨¡å‹...")

    model_path = r'E:\AI_Training\City_Competition\code\runs\detect\train\weights\best.pt'
    dataset_path = r'E:\AI_Training\City_Competition\code\dataset\dataset1\data.yaml'

    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        return

    try:
        model = YOLO(model_path)
        results = model.val(data=dataset_path, split='test', workers=0, plots=False)

        if hasattr(results, 'box') and results.box:
            map50 = getattr(results.box, 'map50', 0)
            map5095 = getattr(results.box, 'map', 0)
            precision = getattr(results.box, 'precision', 0)
            recall = getattr(results.box, 'recall', 0)

            print(f"ğŸ“ˆ mAP@0.5 (æµ‹è¯•é›†): {map50:.4f}")
            print(f"ğŸ“ˆ mAP@0.5:0.95 (æµ‹è¯•é›†): {map5095:.4f}")
            print(f"ğŸ“ˆ Precision (æµ‹è¯•é›†): {precision:.4f}")
            print(f"ğŸ“ˆ Recall (æµ‹è¯•é›†): {recall:.4f}")

            # ç”ŸæˆJSONç»“æœ
            test_results = {
                "model_path": model_path,
                "dataset_path": dataset_path,
                "metrics": {
                    "mAP50": float(map50),
                    "mAP50_95": float(map5095),
                    "precision": float(precision),
                    "recall": float(recall)
                }
            }

            # ä¿å­˜JSONç»“æœ
            json_path = os.path.join(os.path.dirname(model_path), 'test_results.json')
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(test_results, f, ensure_ascii=False, indent=2)
            print(f"ğŸ“„ JSONæµ‹è¯•ç»“æœå·²ä¿å­˜: {json_path}")

            return map50, map5095, precision, recall
        else:
            print("âŒ æ— æ³•è·å–æ¨¡å‹æµ‹è¯•ç»“æœ")
            return 0, 0, 0, 0

    except Exception as e:
        print(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {e}")
        return 0, 0, 0, 0


def main():
    """ä¸»å‡½æ•° - å…ˆå¢å¼ºæ•°æ®ï¼Œå†åˆ’åˆ†æ•°æ®é›†"""
    print("ğŸš€ å¼€å§‹æ•°æ®å¤„ç†æµç¨‹ï¼šæ•°æ®å¢å¼º -> æ•°æ®é›†åˆ’åˆ†")

    # æ•°æ®é›†è·¯å¾„
    dataset_path = r"E:\AI_Training\City_Competition\code\dataset\dataset1"

    # è¯¢é—®æ˜¯å¦éœ€è¦æ•°æ®å¢å¼º
    print("ğŸ” æ£€æŸ¥æ˜¯å¦éœ€è¦æ•°æ®å¢å¼º...")
    augment_choice = input("æ˜¯å¦è¿›è¡Œæ•°æ®å¢å¼ºï¼Ÿ(y/nï¼Œé»˜è®¤ä¸ºy): ").lower().strip()
    if augment_choice in ['', 'y', 'yes']:
        augment_data(dataset_path, augment_count=100)
        print("âœ… æ•°æ®å¢å¼ºå®Œæˆ")

    # è¯¢é—®æ˜¯å¦éœ€è¦æ•°æ®é›†åˆ’åˆ†
    print("\nğŸ” æ£€æŸ¥æ˜¯å¦éœ€è¦æ•°æ®é›†åˆ’åˆ†...")
    split_choice = input("æ˜¯å¦è¿›è¡Œæ•°æ®é›†åˆ’åˆ†ï¼Ÿ(y/nï¼Œé»˜è®¤ä¸ºy): ").lower().strip()
    if split_choice in ['', 'y', 'yes']:
        split_dataset(dataset_path)
        print("âœ… æ•°æ®é›†åˆ’åˆ†å®Œæˆ")

    # è¯¢é—®æ˜¯å¦éœ€è¦åœ¨æµ‹è¯•é›†ä¸Šæµ‹è¯•æ¨¡å‹
    print("\nğŸ” æ£€æŸ¥æ˜¯å¦éœ€è¦åœ¨æµ‹è¯•é›†ä¸Šæµ‹è¯•æ¨¡å‹...")
    test_choice = input("æ˜¯å¦åœ¨æµ‹è¯•é›†ä¸Šæµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹ï¼Ÿ(y/nï¼Œé»˜è®¤ä¸ºy): ").lower().strip()
    if test_choice in ['', 'y', 'yes']:
        test_map50, test_map5095, test_precision, test_recall = test_model_on_test_set()
        print(f"\nğŸ¯ æµ‹è¯•é›†è¯„ä¼°ç»“æœ:")
        print(f"   mAP@0.5: {test_map50:.4f}")
        print(f"   mAP@0.5:0.95(0.5åˆ°0.95çš„å¹³å‡mAP): {test_map5095:.4f}")
        print(f"   Precision(ç²¾ç¡®ç‡): {test_precision:.4f}")
        print(f"   Recall(å¬å›ç‡): {test_recall:.4f}")
        print("âœ… æ¨¡å‹æµ‹è¯•å®Œæˆ")

    print("âœ… å®Œæ•´æ•°æ®å¤„ç†æµç¨‹å®Œæˆ")


if __name__ == "__main__":
    main()